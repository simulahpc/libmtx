@c This file is part of Libmtx.
@c Copyright (C) 2022 James D. Trotter
@c
@c Libmtx is free software: you can redistribute it and/or modify it
@c under the terms of the GNU General Public License as published by
@c the Free Software Foundation, either version 3 of the License, or
@c (at your option) any later version.
@c
@c Libmtx is distributed in the hope that it will be useful, but
@c WITHOUT ANY WARRANTY; without even the implied warranty of
@c MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
@c General Public License for more details.
@c
@c You should have received a copy of the GNU General Public License
@c along with Libmtx.  If not, see <https://www.gnu.org/licenses/>.
@c
@c Authors: James D. Trotter <james@simula.no>
@c Last modified: 2022-01-19
@c
@c Libmtx User Guide: Distributed matrices and vectors.

@node Distributed matrices and vectors
@chapter Distributed matrices and vectors
This chapter describes how to distribute matrices and vectors across
multiple processes, and how to perform various linear algebra
operations on distributed matrices and vectors. The distributed-memory
computing features in Libmtx are implemented using MPI, and,
therefore, you will need to build Libmtx with MPI support. In many
cases, working with distributed matrices and vectors involves
converting to or from Matrix Market format, and it may therefore be a
good idea to read @ref{Distributed Matrix Market files} to understand
how to work with distributed Matrix Market files in Libmtx.

@menu
* Distributed vectors:: Data structures for distributed vectors.
* Distributed matrices:: Data structures for distributed matrices.
@end menu


@node Distributed vectors
@section Distributed vectors
@cindex distributed vector
@tindex struct mtxdistvector
The file @file{libmtx/vector/distvector.h} defines the type
@code{struct mtxdistvector}. This data type builds on top of
@code{struct mtxvector} (see @ref{Vectors}) to provide different
options for the underlying storage and implementation of vector
operations.

The definition of @code{struct mtxdistvector} is shown below.
@example
@code{struct mtxdistvector @{
    MPI_Comm comm;
    int comm_size;
    int rank;
    struct mtxpartition rowpart;
    struct mtxvector interior;
@};}
@end example
Similar to @code{mtxdistfile} (see @ref{Data structures for
distributed Matrix Market files}), the first three struct members of
@code{mtxdistvector} contain information about the group of processes
sharing the distributed vector. This includes their MPI communicator
(@code{comm}), the number of processes (@code{comm_size}) and the rank
of the current process (@code{rank}). Also, @code{rowpart} defines a
partitioning of the vector elements. This is used to determine which
parts of the vector belongs to which process.

The final struct member, @code{interior}, stores the part of the
distributed vector that resides on the current process.


@node Creating distributed vectors
@subsection Creating distributed vectors
@cindex free
@findex mtxdistvector_free
This section describes how to create distributed vectors. But first,
the function @code{mtxdistvector_free} is used to free storage allocated
for a distributed vector.
@example
@code{void mtxdistvector_free(struct mtxdistvector * distvector);}
@end example

@cindex copy
@findex mtxdistvector_init_copy
To create a copy of an existing distributed vector, use the function
@code{mtxdistvector_init_copy}.
@example
@code{int mtxdistvector_init_copy(
    struct mtxdistvector * dst,
    const struct mtxdistvector * src);}
@end example

@cindex copy
@findex mtxdistvector_alloc_copy
If storage for a copy of an existing distributed vector is needed, but
the vector values should not be copied or initialised, use the
function @code{mtxdistvector_alloc_copy}.
@example
@code{int mtxdistvector_alloc_copy(
    struct mtxdistvector * dst,
    const struct mtxdistvector * src);}
@end example

@cindex allocate
@cindex array format
@cindex coordinate format
@findex mtxdistvector_alloc_array
@findex mtxdistvector_alloc_coordinate
To allocate storage for a distributed vector in @emph{array} or
@emph{coordinate} format, the functions
@code{mtxdistvector_alloc_array} or
@code{mtxdistvector_alloc_coordinate} may be used.
@example
@code{int mtxdistvector_alloc_array(
    struct mtxdistvector * vector,
    enum mtxfield field,
    enum mtxprecision precision,
    int num_rows,
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

int mtxdistvector_alloc_coordinate(
    struct mtxdistvector * vector,
    enum mtxfield field,
    enum mtxprecision precision,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example
@noindent
In both cases, the desired field and precision must be specified, as
well as the number of rows in the entire, global vector
(@code{num_rows}). For a vector in coordinate format, it is also
necessary to specify the number of nonzero vector elements
(@code{num_nonzeros}) that will reside @emph{on the current process}.
Note that the vector values are not initialised, and so it is up to
the user to initialise them.

@code{rowpart} must be a partitioning of the rows of the global
vector, which means that @code{rowpart->size} must be equal to
@samp{num_rows}. There may be at most one part in the partition per
MPI process in the communicator @code{comm}.

@findex mtxdistvector_init_@var{type}_@var{field}_@var{precision}
If the vector values are already known, then there are also functions
for allocating a distributed vector and initialising the values
directly. This is done by calling
@code{mtxdistvector_init_@var{type}_@var{field}_@var{precision}},
where @code{@var{type}}, @code{@var{field}} and @code{@var{precision}}
denote the vector type (i.e., @samp{array} or @samp{coordinate}),
field (i.e., @samp{real}, @samp{complex} or @samp{integer}) and
precision (i.e., @samp{single} or @samp{double}).

@findex mtxdistvector_init_array_complex_double
For example, to create a double precision, complex vector in array
format, use @code{mtxdistvector_init_array_complex_double}.
@example
@code{int mtxdistvector_init_array_complex_double(
    struct mtxdistvector * distvector,
    int num_rows,
    const double (* data)[2],
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example
@noindent
Each process provides its local vector entries in the array
@code{data}. The length of the @code{data} array must be at least
@samp{rowpart->part_sizes[rank]}, where @samp{rank} is the rank of the
current process. (If there are fewer parts in the partition than MPI
processes, then the @code{data} array is not used on processes where
@samp{rank} is greater than or equal to
@samp{rowpart->num_parts}. @code{data} may therefore be set to
@samp{NULL} on those processes.)

@findex mtxdistvector_init_coordinate_complex_double
To create a double precision, complex vector in coordinate format, use
@code{mtxdistvector_init_coordinate_complex_double}.
@example
@code{int mtxdistvector_init_coordinate_complex_double(
    struct mtxdistvector * vector,
    int num_rows,
    int64_t num_nonzeros,
    const int * idx,
    const double (* data)[2],
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example
@noindent
The arguments @code{idx} and @code{data} are arrays of length
@code{num_nonzeros}. Each process may provide arrays of different
lengths. Each index @samp{idx[0]}, @samp{idx[1]}, ...,
@samp{idx[num_nonzeros-1]}, is an integer in the range
@samp{[0,N)}, where @samp{N} is the size of the part owned by the
current process, (i.e., @samp{rowpart->part_sizes[rank]}, where
@samp{rank} is the rank of the current process).

Note that duplicate entries are allowed, but this may cause some
operations (e.g., @code{mtxdistvector_dot}, @code{mtxdistvector_nrm2})) to
produce incorrect results.


@node Modifying values of distributed vectors
@subsection Modifying values
@findex mtxdistvector_set_constant_@var{field}_@var{precision}
The functions
@code{mtxdistvector_set_constant_@var{field}_@var{precision}} can be
used to set every (nonzero) value of a vector equal to a constant
scalar, where @code{@var{field}} and @code{@var{precision}} should
match the field (i.e., @samp{real}, @samp{complex} or @samp{integer})
and precision (i.e., @samp{single} or @samp{double}) of
@code{mtxdistvector}.
@findex mtxdistvector_set_constant_@var{field}_@var{precision}
@findex mtxdistvector_set_constant_real_single
@findex mtxdistvector_set_constant_real_double
@findex mtxdistvector_set_constant_complex_single
@findex mtxdistvector_set_constant_complex_double
@findex mtxdistvector_set_constant_integer_single
@findex mtxdistvector_set_constant_integer_double
@example
@code{int mtxdistvector_set_constant_real_single(
    struct mtxdistvector *, float a, struct mtxdisterror * disterr);
int mtxdistvector_set_constant_real_double(
    struct mtxdistvector *, double a, struct mtxdisterror * disterr);
int mtxdistvector_set_constant_complex_single(
    struct mtxdistvector *, float a[2], struct mtxdisterror * disterr);
int mtxdistvector_set_constant_complex_double(
    struct mtxdistvector *, double a[2], struct mtxdisterror * disterr);
int mtxdistvector_set_constant_integer_single(
    struct mtxdistvector *, int32_t a, struct mtxdisterror * disterr);
int mtxdistvector_set_constant_integer_double(
    struct mtxdistvector *, int64_t a, struct mtxdisterror * disterr);}
@end example

To access or modify individual vector elements, the underlying vector
storage is accessed through the appropriate member of the
@code{storage} union in the @code{mtxvector} struct.


@node Converting distributed vectors to and from Matrix Market format
@subsection Converting to and from Matrix Market format
@cindex convert to and from Matrix Market format
@cindex convert to and from distributed Matrix Market format
A distributed vector can be obtained from a Matrix Market file by
distributing the Matrix Market entries across multiple processes
before converting the data on each process to the desired vector
storage format. Typically, this involves partitioning the rows of the
vector and distributing the data accordingly. If the Matrix Market
file is already distributed across several processes, then the data is
partitioned and redistributed before converting to the desired vector
storage format.

Conversely, a distributed vector can be converted directly to
distributed Matrix Market format without the need for redistributing
any data. If desirable, the data may also be gathered onto a single,
root process after converting to Matrix Market format. In either case,
converting to Matrix Market format allows the data to be easily
written to a Matrix Market file.

@findex mtxdistvector_from_mtxfile
To convert a vector in Matrix Market format to @code{struct
mtxdistvector}, the function @code{mtxdistvector_from_mtxfile} can be
used. In this case, the Matrix Market file @code{mtxfile} must reside
on the process whose rank is @code{root}.
@example
@code{int mtxdistvector_from_mtxfile(
    struct mtxdistvector * dst,
    const struct mtxfile * src,
    enum mtxvectortype type,
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    int root,
    struct mtxdisterror * disterr);}
@end example
@noindent
The @code{type} argument may be used to specify a desired storage
format or implementation for the underlying @code{mtxvector} on each
process. If @code{type} is @samp{mtxvector_auto}, then the type of
@code{mtxvector} is chosen to match the type of @code{src}. That is,
@samp{mtxvector_array} is used if @code{src} is in array format, and
@samp{mtxvector_coordinate} is used if @code{src} is in coordinate
format.

Furthermore, @code{rowpart} must be a partitioning of the rows of the
global vector. Therefore, @code{rowpart->size} must be equal to the
number of rows in the underlying vector represented by
@code{mtxfile}. The partition must consist of at most one part for
each MPI process in the communicator @code{comm}. If @code{rowpart} is
@samp{NULL}, then the rows are partitioned into contiguous blocks of
equal size by default.


@findex mtxdistvector_to_mtxfile
To convert @code{struct mtxdistvector} back to Matrix Market format,
the function @code{mtxdistvector_to_mtxfile} can be used.
@example
@code{int mtxdistvector_to_mtxfile(
    const struct mtxdistvector * mtxdistvector,
    struct mtxfile * mtxfile,
    enum mtxfileformat mtxfmt,
    MPI_Comm comm,
    int root,
    struct mtxdisterror * disterr);}
@end example
@noindent
The resulting Matrix Market file resides on the process whose rank is
@code{root}. The vector is stored in array format if @code{mtxfmt} is
@samp{mtxfile_array} or in coordinate format if @code{mtxfmt} is
@samp{mtxfile_coordinate}.


@findex mtxdistvector_from_mtxdistfile
If a Matrix Market file has already been distributed among multiple
processes, then @code{mtxdistvector_from_mtxdistfile} can be used to
obtain a distributed vector with the desired partitioning and storage
format.
@example
@code{int mtxdistvector_from_mtxdistfile(
    struct mtxdistvector * distvector,
    const struct mtxdistfile * mtxdistfile,
    enum mtxvectortype vector_type,
    const struct mtxpartition * rowpart,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example
@noindent
Each process partitions its part of the distributed Matrix Market
file. The data is then redistributed after partitioning.


@findex mtxdistvector_to_mtxdistfile
The function @code{mtxdistvector_to_mtxdistfile} will convert a
distributed vector to a distributed Matrix Market format.
@example
@code{int mtxdistvector_to_mtxdistfile(
    const struct mtxdistvector * distvector,
    struct mtxdistfile * mtxdistfile,
    struct mtxdisterror * disterr);}
@end example
@noindent
In this case, there is no redistribution or communication of the
underlying data.

@node Reading and writing distributed vectors
@subsection Reading and writing Matrix Market files
@cindex file I/O
@cindex reading files
Distributed vectors can be read from or written to files in Matrix
Market format, much in the same way as described for vectors on a
single process in @ref{Reading and writing vectors}. Therefore, the
functions @code{mtxdistvector_read}, @code{mtxdistvector_fread} and
@code{mtxdistvector_gzread} are provided to easily read a vector from
a file in Matrix Market format and distribute it among a group of
processes, before converting it to a desired vector representation on
each process.
@findex mtxdistvector_read
@findex mtxdistvector_fread
@findex mtxdistvector_gzead
@example
@code{int mtxdistvector_read(
    struct mtxdistvector * vector,
    enum mtxprecision precision,
    enum mtxvectortype type,
    const char * path,
    bool gzip,
    int * lines_read,
    int64_t * bytes_read);

int mtxdistvector_fread(
    struct mtxdistvector * vector,
    enum mtxprecision precision,
    enum mtxvectortype type,
    FILE * f,
    int * lines_read,
    int64_t * bytes_read,
    size_t line_max,
    char * linebuf);

int mtxdistvector_gzread(
    struct mtxdistvector * vector,
    enum mtxprecision precision,
    enum mtxvectortype type,
    gzFile f,
    int * lines_read,
    int64_t * bytes_read,
    size_t line_max,
    char * linebuf);}
@end example
@noindent
Here @code{type} specifies a format to use for representing the
vector, whereas @code{precision} specifies the precision to use for
representing individual vector values. If @code{type} is
@samp{mtxvector_auto}, then the underlying vector is stored in array
format or coordinate format, depending on the format of the Matrix
Market file. Otherwise, an attempt is made to convert the vector to
the desired type. The remaining arguments are used in the same way as
described in @ref{Reading Matrix Market files}.

@cindex writing files
@findex mtxdistvector_write
@findex mtxdistvector_fwrite
@findex mtxdistvector_gzwrite
Conversely, the functions @code{mtxdistvector_write},
@code{mtxdistvector_fwrite} and @code{mtxdistvector_gzwrite} are
provided to write a vector to a file in Matrix Market format.
@example
@code{int mtxdistvector_write(
    const struct mtxdistvector * vector,
    enum mtxfileformat mtxfmt,
    const char * path,
    bool gzip,
    const char * fmt,
    int64_t * bytes_written);

int mtxdistvector_fwrite(
    const struct mtxdistvector * vector,
    enum mtxfileformat mtxfmt,
    FILE * f,
    const char * fmt,
    int64_t * bytes_written);

int mtxdistvector_gzwrite(
    const struct mtxdistvector * vector,
    enum mtxfileformat mtxfmt,
    gzFile f,
    const char * fmt,
    int64_t * bytes_written);}
@end example
@noindent
The @code{mtxfmt} argument may be used to specify whether the vector
should be written in array or coordinate format.

@node Level 1 BLAS for distributed vectors
@subsection Level 1 BLAS
@cindex BLAS
The same BLAS routines that were described in @ref{Level 1 BLAS for
vectors} are also available for distributed vectors. The main
difference is that each function takes an extra argument of type
@code{struct mtxdisterror} to allow for robust error handling in a
distributed setting (see @ref{Distributed error handling}). In
addition, some of the level 1 BLAS routines require processes to
communicate with one another to produce the correct result. In
particular, computing dot products and norms typically require a
reduction (e.g., @code{MPI_Allreduce}) among all processes involved.

This section briefly describes the level 1 BLAS functions for
distributed vectors.

@findex mtxdistvector_swap
@findex mtxdistvector_copy
The function @code{mtxdistvector_swap} swaps the values of two
vectors, whereas @code{mtxdistvector_copy} copies the values from one
vector to another. Both operations are performed without any
communication.
@example
@code{int mtxdistvector_swap(
    struct mtxdistvector * x,
    struct mtxdistvector * y,
    struct mtxdisterror * disterr);

int mtxdistvector_copy(
    struct mtxdistvector * y,
    const struct mtxdistvector * x,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_sscal
@findex mtxdistvector_dscal
The functions @code{mtxdistvector_sscal} and
@code{mtxdistvector_dscal} scale a vector @code{x} by a floating point
constant @code{a} in single or double precision, respectively. That
is, @code{x = a*x}. This operation does not require communication
between processes.
@example
@code{int mtxdistvector_sscal(
    float a,
    struct mtxdistvector * x,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_dscal(
    double a,
    struct mtxdistvector * x,
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example
@noindent
If @code{num_flops} is not @samp{NULL}, then it is used to return the
total number of floating point operations performed by all processes.

@findex mtxdistvector_saxpy
@findex mtxdistvector_daxpy
@findex mtxdistvector_saypx
@findex mtxdistvector_daypx
The functions @code{mtxdistvector_saxpy}, @code{mtxdistvector_daxpy},
@code{mtxdistvector_saypx} and @code{mtxdistvector_daypx} add together
vectors multiplied by a single or double precision floating point
value, @code{y = a*x + y} or @code{y = a*y + x}. This may also be done
without needing to perform communication.
@example
@code{int mtxdistvector_saxpy(
    float a,
    const struct mtxdistvector * x,
    struct mtxdistvector * y,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_daxpy(
    double a,
    const struct mtxdistvector * x,
    struct mtxdistvector * y,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_saypx(
    float a,
    struct mtxdistvector * y,
    const struct mtxdistvector * x,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_daypx(
    double a,
    struct mtxdistvector * y,
    const struct mtxdistvector * x,
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_sdot
@findex mtxdistvector_ddot
The functions @code{mtxdistvector_sdot} and @code{mtxdistvector_ddot}
compute the Euclidean dot product of two real- or integer-valued
vectors. This performs a reduction among all processes involved to
produce the final result.
@example
@code{int mtxdistvector_sdot(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    float * dot,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_ddot(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    double * dot,
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_cdotu
@findex mtxdistvector_zdotu
@findex mtxdistvector_cdotc
@findex mtxdistvector_zdotc
For complex vectors, the functions @code{mtxdistvector_cdotu} and
@code{mtxdistvector_zdotu} compute the product of the transpose of a
complex row vector with another complex row vector, @code{x^T*y},
where @code{x^T} denotes the transpose of @code{x}. The functions
@code{mtxdistvector_cdotc} and @code{mtxdistvector_zdotc} compute the
Euclidean dot product of two complex vectors, @code{x^H*y}, where
@code{x^H} denotes the conjugate transpose of @code{x}.
@example
@code{int mtxdistvector_cdotu(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    float (* dot)[2],
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_zdotu(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    double (* dot)[2],
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_cdotc(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    float (* dot)[2],
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_zdotc(
    const struct mtxdistvector * x,
    const struct mtxdistvector * y,
    double (* dot)[2],
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_snrm2
@findex mtxdistvector_dnrm2
The functions @code{mtxdistvector_snrm2} and
@code{mtxdistvector_dnrm2} compute the Euclidean norm of a vector. in
single and double precision floating point, respectively.
@example
@code{int mtxdistvector_snrm2(
    const struct mtxdistvector * x,
    float * nrm2,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_dnrm2(
    const struct mtxdistvector * x,
    double * nrm2,
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_sasum
@findex mtxdistvector_dasum
The functions @code{mtxdistvector_sasum} and
@code{mtxdistvector_dasum} compute the sum of absolute values, or
1-norm, of a vector. in single and double precision floating point,
respectively. If the vector is complex-valued, then the sum of the
absolute values of the real and imaginary parts is computed. A
reduction is performed to combine the values computed by each process.
@example
@code{int mtxdistvector_sasum(
    const struct mtxdistvector * x,
    float * asum,
    int64_t * num_flops,
    struct mtxdisterror * disterr);

int mtxdistvector_dasum(
    const struct mtxdistvector * x,
    double * asum,
    int64_t * num_flops,
    struct mtxdisterror * disterr);}
@end example

@findex mtxdistvector_iamax
The function @code{mtxdistvector_iamax} finds the index of the first
element having the largest absolute value among all the vector
elements. If the vector is complex-valued, then the index points to
the first element having the maximum sum of the absolute values of the
real and imaginary parts.
@example
@code{int mtxdistvector_iamax(
    const struct mtxdistvector * x,
    int * iamax,
    struct mtxdisterror * disterr);}
@end example


@node Distributed matrices
@section Distributed matrices
@cindex distributed matrix
@tindex struct mtxdistmatrix
The file @file{libmtx/distmatrix/distmatrix.h} defines the type
@code{struct mtxdistmatrix}. This data type builds on top of
@code{struct mtxmatrix} (see @ref{Matrices}) to offer different options
for the underlying storage and implementation of matrix operations.
@example
@code{struct mtxdistmatrix @{
    MPI_Comm comm;
    int comm_size;
    int rank;
    struct mtxmatrix interior;
@};}
@end example
@noindent
Similar to @code{mtxdistfile} (see @ref{Data structures for
distributed Matrix Market files}), The first three struct members of
@code{mtxdistmatrix} contain information about the group of processes
sharing the distributed matrix. This includes their MPI communicator
(@code{comm}), the number of processes (@code{comm_size}) and the rank
of the current process (@code{rank}). The matrix, @code{interior},
stores the part of the distributed matrix that resides on the current
process.

@node Halo exchange
@subsection Halo exchange
@cindex halo exchange
Some linear algebra operations, such as matrix-vector multiplication,
require communication between MPI processes whenever distributed
matrices and vectors are used. This kind of communication is commonly
implemented through a @dfn{halo exchange}. This section describes data
structures for representing vector halos, and how to perform halo
exchanges.



@c @node Data distribution
@c @subsection Data distribution

@c @cindex data distribution
@c @cindex distributed matrix
@c @cindex distributed vector
@c @cindex block distribution
@c @cindex cyclic distribution
@c @cindex block-cyclic distribution
@c @cindex discrete distribution
@c @tindex mtx_distribution
@c It is often necessary to distribute large matrices and vectors across
@c multiple processes, both for the purpose of performing computations in
@c parallel and also to use multiple nodes, thereby increasing the total
@c amount of available memory.  To facilitate such data distribution,
@c some additional information is stored in the @code{mtx} struct.

@c First, we define the additional enum type @code{mtx_distribution},
@c which describes different methods for distributing a one-dimensional
@c data structure, such as a vector, among multiple processes.  Matrices
@c are distributed by independently specifying the distributions of the
@c rows and columns.
@c @example
@c @code{enum mtx_distribution @{
@c     mtx_private,           /* owned by a single process */
@c     mtx_replicated,        /* replicated across every process */
@c     mtx_block,             /* block distribution */
@c     mtx_cyclic,            /* cyclic distribution */
@c     mtx_block_cyclic,      /* block-cyclic distribution */
@c     mtx_discrete,          /* discrete distribution */
@c @};}
@c @end example
@c By default, matrices and vectors are not distributed
@c (@code{mtx_private}).  That is, the entries of a vector and the rows
@c and columns of a matrix are owned by a single process.

@c For a distributed vector, @code{mtx_block} is used when the vector is
@c partitioned into contiguous blocks of roughly equal size and one block
@c is assigned to each process.  In contrast, @code{mtx_cyclic} assigns
@c consecutive entries of the vector to successive processes.  By
@c generalising the block and cyclic distributions,
@c @code{mtx_block_cyclic} assigns consecutive, fixed-size blocks to
@c successive processes.  Finally, @code{mtx_discrete} allows an
@c arbitrary assignment of global vector entries to processes.


@c @cindex cover
@c @cindex partition
@c @tindex mtxpartitioning
@c The enum type @code{mtxpartitioning}, is used to describe whether the
@c rows and columns of a distributed matrix or vector form a partition or
@c merely a cover of the rows and columns of a global matrix or
@c vector. In the case of a partition, each matrix or vector entry is
@c owned by a single MPI process. In the case of a cover, different MPI
@c processes are allowed to store values associated with the same matrix
@c or vector entry.
@c @example
@c @code{enum mtxpartitioning @{
@c     mtxpartition,   /* matrix/vector entries are owned
@c                          * by a single MPI process. */
@c     mtx_cover,       /* matrix/vector entries may be owned
@c                          * by multiple MPI processes. */
@c @};}
@c @end example
@c Note that some algorithms may only work with a partitioned matrix and
@c might produce incorrect results in the case of a covering. Thus, it
@c may be necessary to first perform a reduction to combine values
@c associated with matrix or vector entries that are distributed across
@c multiple MPI processes.


@c @node Index sets
@c @subsection Index sets

@c @cindex Index set
@c An @dfn{index set} is a set of integers, typically used to represent a
@c subset of the rows of a vector or the rows or columns of a
@c matrix. Index sets are used, for example, when specifying submatrices
@c of a matrix, or for partitioning and distributing matrices and vectors
@c among multiple processes.

@c @tindex struct mtxidxset
@c @tindex enum mtxidxsettype
@c The file @file{libmtx/util/index_set.h} defines data types for index
@c sets, including @code{struct mtxidxset}. There are different types
@c of index sets, which may be distinguished by the enum type
@c @code{mtxidxsettype}.
@c @itemize
@c @item @code{mtxidxset_interval}
@c represents an index set of contiguous integers from a half-open
@c interval @code{[a,b)}.

@c @item @code{mtxidxset_array}
@c represents a discrete index set, which is not necessarily contiguous,
@c as an array of integers.

@c @end itemize

@c An index set representing a half-open interval @code{[a,b)} can be
@c created with @code{mtxidxset_init_interval}.
@c @findex mtxidxset_init_interval
@c @example
@c @code{int mtxidxset_init_interval(
@c     struct mtxidxset * index_set, int a, int b);}
@c @end example
@c Then, the function @code{mtxidxset_contains} can be used to test if
@c a given integer @code{n} belongs to the index set.
@c @findex mtxidxset_contains
@c @example
@c @code{bool mtxidxset_contains(
@c     const struct mtxidxset * index_set, int n);}
@c @end example
