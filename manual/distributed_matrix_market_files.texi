@c This file is part of libmtx.
@c Copyright (C) 2022 James D. Trotter
@c
@c libmtx is free software: you can redistribute it and/or modify it
@c under the terms of the GNU General Public License as published by
@c the Free Software Foundation, either version 3 of the License, or
@c (at your option) any later version.
@c
@c libmtx is distributed in the hope that it will be useful, but
@c WITHOUT ANY WARRANTY; without even the implied warranty of
@c MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
@c General Public License for more details.
@c
@c You should have received a copy of the GNU General Public License
@c along with libmtx.  If not, see <https://www.gnu.org/licenses/>.
@c
@c Authors: James D. Trotter <james@simula.no>
@c Last modified: 2022-01-07
@c
@c libmtx User Guide: Distributed Matrix Market files.

@node Distributed Matrix Market files
@chapter Distributed Matrix Market files

This chapter describes how to distribute Matrix Market files among
multiple processes using MPI, and how to perform various operations on
those files in a distributed manner. The distributed-memory computing
features in libmtx are implemented using MPI, and you will therefore
need to build libmtx with MPI support.

For most user-facing types and functions that relate to distributed
computing, libmtx uses the convention of prefixing their names with
@code{mtxdist}. This makes it easier to avoid possible name clashes
with other code when using libmtx, and also to distinguish parts of a
program that rely on distributed computing from those parts that are
not distributed.

@menu
* Error handling: Error handling for distributed Matrix Market files.  How to handle errors when using libmtx for distributed computing.
* Data structures: Distributed Matrix Market files: data structures. Basic data structures for representing distributed @file{mtx} files.
* Creating distributed Matrix Market files:: How to create distributed @file{mtx} files.
* Modifying values: Distributed Matrix Market files: modifying values. Functions for changing matrix or vector values.
* Converting to and from distributed Matrix Market files:: Functions for converting to and from distributed @file{mtx} files
* Reading and writing distributed Matrix Market files:: Functions for reading from and writing to files in Matrix Market format.
* Transposing, sorting and reordering: Distributed Matrix Market files: transposing@comma{} sorting and reordering. Functions for transposing, sorting and reordering distributed @file{mtx} files.
@end menu

@node Error handling for distributed Matrix Market files
@section Error handling
@cindex error handling
In addition to the error handling routines described in @ref{Error
handling}, libmtx provides some additional error handling
functionality when working with MPI and distributed data. First, some
MPI functions may return an error code on failure, which should be
handled correctly. Second, whenever multiple processes are involved,
there are cases where only one or a few of those processes may
encounter errors. These errors must be handled appropriately to ensure
accurate reporting and that the program exits in a graceful manner
instead of hanging indefinitely.

@subsection MPI errors
@findex mtxdiststrerror
Some functions in libmtx may fail due to MPI errors. In these cases,
some additional information is needed to provide helpful error
descriptions, and the function @code{mtxdiststrerror} should be used
(instead of @code{mtxstrerror}).
@example
@code{const char * mtxdiststrerror(
    int err, int mpierrcode, char * mpierrstr);}
@end example
The error code @code{err} is an integer corresponding to one of the
error codes from the @code{mtxerror} enum type. The arguments
@code{mpierrcode} and @code{mpierrstr} are only used if @code{err} is
@samp{MTX_ERR_MPI}.

@findex MPI_Error_string
@cindex @code{MPI_MAX_ERROR_STRING}
If @code{err} is @samp{MTX_ERR_MPI}, then the argument
@code{mpierrcode} should be set to the error code that was returned
from the MPI function call that failed. In addition, the argument
@code{mpierrstr} must be a char array whose length is at least equal
to @code{MPI_MAX_ERROR_STRING}. Internally, @code{mtxdiststrerror}
uses @code{MPI_Error_string} to obtain a description of the error.

The example below shows how @code{mtxdiststrerror} is typically used.
@example
@code{int err, mpierr;
char mpierrstr[MPI_MAX_ERROR_STRING];
struct mtxdisterror disterr;
err = mtxdisterror_alloc(&disterr, MPI_COMM_WORLD, &mpierr);
if (err) @{
    fprintf(stderr, "error: %s\n",
            mtxdiststrerror(err, mpierr, mpierrstr));
    MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);
@}}
@end example
If @code{mtxdisterror_alloc} returns @samp{MTX_ERR_MPI} and
@code{mpierr} is set to @samp{MPI_ERR_COMM}, then the following
message will be printed:
@example
@code{error: MPI_ERR_COMM: invalid communicator}
@end example


@subsection Distributed error handling
@tindex struct mtxdisterror
To more easily handle errors in cases where one or more processes may
fail, libmtx uses the data type @code{struct mtxdisterror}. Most of
the functions in libmtx that involve distributed computing take an
additional argument of type @code{struct mtxdisterror} to provide
robust error handling in these cases.

@findex mtxdisterror_alloc
To use @code{struct mtxdisterror}, one must first allocate storage
using @code{mtxdisterror_alloc}.
@example
@code{int mtxdisterror_alloc(
    struct mtxdisterror * disterr,
    MPI_Comm comm,
    int * mpierrcode);}
@end example
An example of this was already shown in the previous section.

@findex mtxdisterror_free
Note that the storage allocated for @code{mtxdisterror} should be
freed by calling @code{mtxdisterror_free}.
@example
@code{void mtxdisterror_free(struct mtxdisterror * disterr);}
@end example

@findex mtxdisterror_description
If an error occurs, then a description of the error can be obtained by
calling @code{mtxdisterror_description}.
@example
@code{char * mtxdisterror_description(struct mtxdisterror * disterr);}
@end example
Note that if @code{mtxdisterror_description} is called more than once,
the pointer that was returned from the previous call will no longer be
valid and using it will result in a use-after-free error.

@findex mtxdisterror_allreduce
Finally, the function @code{mtxdisterror_allreduce} can be used to
communicate error status among multiple processes.
@example
@code{int mtxdisterror_allreduce(struct mtxdisterror * disterr, int err);}
@end example
More specifically, @code{mtxdisterror_allreduce} performs a collective
reduction on error codes provided by each MPI process in the
communicator used by @code{disterr}. This is the same MPI communicator
that was provided as the @code{comm} argument to
@code{mtxdisterror_alloc}.

Because @code{mtxdisterror_allreduce} is a collective operation, it
must be performed by every process in the communicator of
@code{disterr}. Otherwise, the program may hang indefinitely.

Each process gathers the error code and rank of every other process.
If the error code of each and every process is @samp{MTX_SUCCESS},
then @code{mtxdisterror_allreduce} returns
@samp{MTX_SUCCESS}. Otherwise, @samp{MTX_ERR_MPI_COLLECTIVE} is
returned.  Moreover, the rank and error code of each process is stored
in @code{disterr}.

If the error code @code{err} is @samp{MTX_ERR_MPI_COLLECTIVE}, then it
is assumed that a reduction has already been performed, and
@code{mtxdisterror_allreduce} returns immediately with
@samp{MTX_ERR_MPI_COLLETIVE}. As a result, if any process calls
@code{mtxdisterror_allreduce} with @code{err} set to
@samp{MTX_ERR_MPI_COLLETIVE}, then every other process in the
communicator must also set @code{err} to
@samp{MTX_ERR_MPI_COLLECTIVE}, or else the program may hang
indefinitely.

The following example shows how @code{mtxdisterror_allreduce} is used.
@example
@code{int err;
struct mtxdisterror disterr;
err = mtxdisterror_alloc(&disterr, MPI_COMM_WORLD);
if (err)
    MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);

// Get the MPI rank of the current process.
// Perform an all-reduction on the error code from
// MPI_Comm_rank, so that if any process fails,
// then we can exit gracefully.
int comm_err, rank;
err = MPI_Comm_rank(MPI_COMM_WORLD, &rank);
comm_err = mtxdisterror_allreduce(&disterr, err);
if (comm_err)
    return comm_err;

...}
@end example


@node Distributed Matrix Market files: data structures
@section Data structures
@tindex struct mtxdistfile
The file @file{libmtx/mtxdistfile/mtxdistfile.h} defines the type
@code{struct mtxdistfile}, which is used to represent a Matrix Market
file distributed among one or more MPI processes. The definition of
the @code{mtxdistfile} struct is shown below.
@example
@code{struct mtxdistfile @{
    MPI_Comm comm;
    int comm_size;
    int rank;
    struct mtxfileheader header;
    struct mtxfilecomments comments;
    struct mtxfilesize size;
    enum mtxprecision precision;
    struct mtxfile mtxfile;
@};}
@end example
The first three struct members contain some information about the
group of processes sharing the distributed Matrix Market file,
including their MPI communicator (@code{comm}), the number of
processes (@code{comm_size}) and the rank of the current process
(@code{rank}). Thereafter, follow the header line, comments, size line
and the chosen precision, all of which must be identical on every
process in the communicator. Finally, @code{mtxfile} represents the
part of the Matrix Market file that resides on the current process.

@node Creating distributed Matrix Market files
@section Creating distributed Matrix Market files
Constructing distributed Matrix Market files works in much the same
way as the non-distributed case, which was described in @ref{Creating
Matrix Market files}.

If the needed data has already been distributed, then
@code{mtxdistfile_init} can be used to create a distributed Matrix
Market file from Matrix Market files residing on each process in a
communicator.

This function performs collective communication and therefore requires
every process in the communicator to perform matching calls to the
function. The communicator must be the same one that was used to
allocate @code{disterr}.
@example
@code{int mtxdistfile_init(
    struct mtxdistfile * mtxdistfile,
    const struct mtxfile * mtxfile,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example

The function @code{mtxdistfile_free} frees storage allocated for a
distributed Matrix Market file.
@example
@code{void mtxdistfile_free(struct mtxdistfile * mtxdistfile);}
@end example

@example
@code{
/**
 * ‘mtxdistfile_alloc_copy()’ allocates storage for a copy of a
 * distributed Matrix Market file without initialising the underlying
 * values.
 */
int mtxdistfile_alloc_copy(
    struct mtxdistfile * dst,
    const struct mtxdistfile * src,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_copy()’ creates a copy of a distributed Matrix
 * Market file.
 */
int mtxdistfile_init_copy(
    struct mtxdistfile * dst,
    const struct mtxdistfile * src,
    struct mtxdisterror * disterr);}
@end example

In addition, there are functions for allocating storage for and
initialising distributed matrices and vector in array and coordinate
format.
@example
@code{/**
 * ‘mtxdistfile_alloc_matrix_array()’ allocates a distributed matrix
 * in array format.
 */
int mtxdistfile_alloc_matrix_array(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilefield field,
    enum mtxfilesymmetry symmetry,
    enum mtxprecision precision,
    int num_rows,
    int num_columns,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_real_single()’ allocates and
 * initialises a distributed matrix in array format with real, single
 * precision coefficients.
 */
int mtxdistfile_init_matrix_array_real_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const float * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_real_double()’ allocates and initialises
 * a matrix in array format with real, double precision coefficients.
 */
int mtxdistfile_init_matrix_array_real_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_complex_single()’ allocates and
 * initialises a distributed matrix in array format with complex,
 * single precision coefficients.
 */
int mtxdistfile_init_matrix_array_complex_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const float (* data)[2],
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_complex_double()’ allocates and
 * initialises a matrix in array format with complex, double precision
 * coefficients.
 */
int mtxdistfile_init_matrix_array_complex_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const double (* data)[2],
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_integer_single()’ allocates and
 * initialises a distributed matrix in array format with integer,
 * single precision coefficients.
 */
int mtxdistfile_init_matrix_array_integer_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const int32_t * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_array_integer_double()’ allocates and
 * initialises a matrix in array format with integer, double precision
 * coefficients.
 */
int mtxdistfile_init_matrix_array_integer_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    const int64_t * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/*
 * Vector array formats
 */

/**
 * ‘mtxdistfile_alloc_vector_array()’ allocates a distributed vector
 * in array format.
 */
int mtxdistfile_alloc_vector_array(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilefield field,
    enum mtxprecision precision,
    int num_rows,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_real_single()’ allocates and
 * initialises a distributed vector in array format with real, single
 * precision coefficients.
 */
int mtxdistfile_init_vector_array_real_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const float * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_real_double()’ allocates and initialises
 * a vector in array format with real, double precision coefficients.
 */
int mtxdistfile_init_vector_array_real_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_complex_single()’ allocates and
 * initialises a distributed vector in array format with complex,
 * single precision coefficients.
 */
int mtxdistfile_init_vector_array_complex_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const float (* data)[2],
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_complex_double()’ allocates and
 * initialises a vector in array format with complex, double precision
 * coefficients.
 */
int mtxdistfile_init_vector_array_complex_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const double (* data)[2],
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_integer_single()’ allocates and
 * initialises a distributed vector in array format with integer,
 * single precision coefficients.
 */
int mtxdistfile_init_vector_array_integer_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const int32_t * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_array_integer_double()’ allocates and
 * initialises a vector in array format with integer, double precision
 * coefficients.
 */
int mtxdistfile_init_vector_array_integer_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    const int64_t * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/*
 * Matrix coordinate formats
 */

/**
 * ‘mtxdistfile_alloc_matrix_coordinate()’ allocates a distributed
 * matrix in coordinate format.
 */
int mtxdistfile_alloc_matrix_coordinate(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilefield field,
    enum mtxfilesymmetry symmetry,
    enum mtxprecision precision,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_real_single()’ allocates and
 * initialises a distributed matrix in coordinate format with real,
 * single precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_real_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_real_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_real_double()’ allocates and
 * initialises a matrix in coordinate format with real, double
 * precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_real_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_real_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_complex_single()’ allocates and
 * initialises a distributed matrix in coordinate format with complex,
 * single precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_complex_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_complex_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_complex_double()’ allocates and
 * initialises a matrix in coordinate format with complex, double
 * precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_complex_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_complex_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_integer_single()’ allocates and
 * initialises a distributed matrix in coordinate format with integer,
 * single precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_integer_single(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_integer_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_integer_double()’ allocates and
 * initialises a matrix in coordinate format with integer, double
 * precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_integer_double(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_integer_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_matrix_coordinate_pattern()’ allocates and
 * initialises a matrix in coordinate format with boolean (pattern)
 * precision coefficients.
 */
int mtxdistfile_init_matrix_coordinate_pattern(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilesymmetry symmetry,
    int num_rows,
    int num_columns,
    int64_t num_nonzeros,
    const struct mtxfile_matrix_coordinate_pattern * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/*
 * Vector coordinate formats
 */

/**
 * ‘mtxdistfile_alloc_vector_coordinate()’ allocates a distributed
 * vector in coordinate format.
 */
int mtxdistfile_alloc_vector_coordinate(
    struct mtxdistfile * mtxdistfile,
    enum mtxfilefield field,
    enum mtxprecision precision,
    int num_rows,
    int64_t num_nonzeros,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_real_single()’ allocates and
 * initialises a distributed vector in coordinate format with real,
 * single precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_real_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_real_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_real_double()’ allocates and
 * initialises a vector in coordinate format with real, double
 * precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_real_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_real_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_complex_single()’ allocates and
 * initialises a distributed vector in coordinate format with complex,
 * single precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_complex_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_complex_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_complex_double()’ allocates and
 * initialises a vector in coordinate format with complex, double
 * precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_complex_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_complex_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_integer_single()’ allocates and
 * initialises a distributed vector in coordinate format with integer,
 * single precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_integer_single(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_integer_single * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_integer_double()’ allocates and
 * initialises a vector in coordinate format with integer, double
 * precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_integer_double(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_integer_double * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);

/**
 * ‘mtxdistfile_init_vector_coordinate_pattern()’ allocates and
 * initialises a vector in coordinate format with boolean (pattern)
 * precision coefficients.
 */
int mtxdistfile_init_vector_coordinate_pattern(
    struct mtxdistfile * mtxdistfile,
    int num_rows,
    int64_t num_nonzeros,
    const struct mtxfile_vector_coordinate_pattern * data,
    MPI_Comm comm,
    struct mtxdisterror * disterr);}
@end example


@node Distributed Matrix Market files: modifying values
@section Modifying values
@findex mtxdistfile_set_constant_real_single
@findex mtxdistfile_set_constant_real_double
@findex mtxdistfile_set_constant_complex_single
@findex mtxdistfile_set_constant_complex_double
@findex mtxdistfile_set_constant_integer_single
@findex mtxdistfile_set_constant_integer_double
@code{mtxdistfile_set_constant_real_single} sets every (nonzero) value
of a distributed Matrix Market file equal to a constant, single
precision floating point number.
@example
@code{int mtxdistfile_set_constant_real_single(
    struct mtxdistfile * mtxdistfile,
    float a,
    struct mtxdisterror * disterr);

int mtxdistfile_set_constant_real_double(
    struct mtxdistfile * mtxdistfile,
    double a,
    struct mtxdisterror * disterr);

int mtxdistfile_set_constant_complex_single(
    struct mtxdistfile * mtxdistfile,
    float a[2],
    struct mtxdisterror * disterr);

int mtxdistfile_set_constant_complex_double(
    struct mtxdistfile * mtxdistfile,
    float a[2],
    struct mtxdisterror * disterr);

int mtxdistfile_set_constant_integer_single(
    struct mtxdistfile * mtxdistfile,
    int32_t a,
    struct mtxdisterror * disterr);

int mtxdistfile_set_constant_integer_double(
    struct mtxdistfile * mtxdistfile,
    int32_t a,
    struct mtxdisterror * disterr);}
@end example

@node Converting to and from distributed Matrix Market files
@section Converting to and from distributed Matrix Market files
This section describes how to convert a Matrix Market file that
resides on a single process to a Matrix Market file that is
distributed among multiple processes.

@findex mtxdistfile_from_mtxfile
@code{mtxdistfile_from_mtxfile} creates a distributed Matrix Market
file from a Matrix Market file stored on a single root process by
distributing the data of the underlying matrix or vector among
processes in a communicator.
@example
@code{int mtxdistfile_from_mtxfile(
    struct mtxdistfile * dst,
    const struct mtxfile * src,
    MPI_Comm comm,
    int root,
    struct mtxdisterror * disterr);}
@end example
This function performs collective communication and therefore requires
every process in the communicator to perform matching calls to this
function.


@node Reading and writing distributed Matrix Market files
@section Reading and writing distributed Matrix Market files


@node Distributed Matrix Market files: transposing@comma{} sorting and reordering
@section Transposing, sorting and reordering



@c This section describes the basic data types used to represent
@c distributed matrices and vectors.

@c @tindex struct mtxdist
@c @tindex mtxdist
@c The file @file{libmtx/mtxdist.h} defines the @code{struct
@c mtxdist} type, which is used to represent distributed objects in the
@c Matrix Market format. The definition of the @code{mtxdist} struct is shown
@c below.
@c @example
@c @code{struct mtxdist @{
@c   /* Data distribution */
@c   MPI_Comm comm;
@c   enum mtx_distribution row_distribution;
@c   enum mtx_distribution column_distribution;
@c   int64_t num_global_rows;
@c   int64_t num_global_columns;
@c   int num_block_rows;
@c   int num_block_columns;
@c   int block_row_size;
@c   int block_column_size;
@c   int block_row;
@c   int block_column;
@c   int64_t * global_rows;
@c   int64_t * global_columns;

@c   /* Matrix Market object */
@c   struct mtx * mtx;
@c @};}
@c @end example

@c The @code{mtxdist} struct contains information about how the
@c underlying matrix or vector is distributed among processes.  It also
@c contains a member of type @code{struct mtx}, which, on a given MPI
@c process, represents the underlying, local matrix of the current
@c process.


@c The following sections provide a detailed explanation of the
@c @code{mtxdist} struct members and their data types.


@c @node Data distribution
@c @subsection Data distribution

@c @cindex data distribution
@c @cindex distributed matrix
@c @cindex distributed vector
@c @cindex block distribution
@c @cindex cyclic distribution
@c @cindex block-cyclic distribution
@c @cindex discrete distribution
@c @tindex mtx_distribution
@c It is often necessary to distribute large matrices and vectors across
@c multiple processes, both for the purpose of performing computations in
@c parallel and also to use multiple nodes, thereby increasing the total
@c amount of available memory.  To facilitate such data distribution,
@c some additional information is stored in the @code{mtx} struct.

@c First, we define the additional enum type @code{mtx_distribution},
@c which describes different methods for distributing a one-dimensional
@c data structure, such as a vector, among multiple processes.  Matrices
@c are distributed by independently specifying the distributions of the
@c rows and columns.
@c @example
@c @code{enum mtx_distribution @{
@c     mtx_private,           /* owned by a single process */
@c     mtx_replicated,        /* replicated across every process */
@c     mtx_block,             /* block distribution */
@c     mtx_cyclic,            /* cyclic distribution */
@c     mtx_block_cyclic,      /* block-cyclic distribution */
@c     mtx_discrete,          /* discrete distribution */
@c @};}
@c @end example
@c By default, matrices and vectors are not distributed
@c (@code{mtx_private}).  That is, the entries of a vector and the rows
@c and columns of a matrix are owned by a single process.

@c For a distributed vector, @code{mtx_block} is used when the vector is
@c partitioned into contiguous blocks of roughly equal size and one block
@c is assigned to each process.  In contrast, @code{mtx_cyclic} assigns
@c consecutive entries of the vector to successive processes.  By
@c generalising the block and cyclic distributions,
@c @code{mtx_block_cyclic} assigns consecutive, fixed-size blocks to
@c successive processes.  Finally, @code{mtx_discrete} allows an
@c arbitrary assignment of global vector entries to processes.


@c @cindex cover
@c @cindex partition
@c @tindex mtx_partitioning
@c The enum type @code{mtx_partitioning}, is used to describe whether the
@c rows and columns of a distributed matrix or vector form a partition or
@c merely a cover of the rows and columns of a global matrix or
@c vector. In the case of a partition, each matrix or vector entry is
@c owned by a single MPI process. In the case of a cover, different MPI
@c processes are allowed to store values associated with the same matrix
@c or vector entry.
@c @example
@c @code{enum mtx_partitioning @{
@c     mtx_partition,   /* matrix/vector entries are owned
@c                          * by a single MPI process. */
@c     mtx_cover,       /* matrix/vector entries may be owned
@c                          * by multiple MPI processes. */
@c @};}
@c @end example
@c Note that some algorithms may only work with a partitioned matrix and
@c might produce incorrect results in the case of a covering. Thus, it
@c may be necessary to first perform a reduction to combine values
@c associated with matrix or vector entries that are distributed across
@c multiple MPI processes.


@c @node Index sets
@c @subsection Index sets

@c @cindex Index set
@c An @dfn{index set} is a set of integers, typically used to represent a
@c subset of the rows of a vector or the rows or columns of a
@c matrix. Index sets are used, for example, when specifying submatrices
@c of a matrix, or for partitioning and distributing matrices and vectors
@c among multiple processes.

@c @tindex struct mtx_index_set
@c @tindex enum mtx_index_set_type
@c The file @file{libmtx/util/index_set.h} defines data types for index
@c sets, including @code{struct mtx_index_set}. There are different types
@c of index sets, which may be distinguished by the enum type
@c @code{mtx_index_set_type}.
@c @itemize
@c @item @code{mtx_index_set_interval}
@c represents an index set of contiguous integers from a half-open
@c interval @code{[a,b)}.

@c @item @code{mtx_index_set_array}
@c represents a discrete index set, which is not necessarily contiguous,
@c as an array of integers.

@c @end itemize

@c An index set representing a half-open interval @code{[a,b)} can be
@c created with @code{mtx_index_set_init_interval}.
@c @findex mtx_index_set_init_interval
@c @example
@c @code{int mtx_index_set_init_interval(
@c     struct mtx_index_set * index_set, int a, int b);}
@c @end example
@c Then, the function @code{mtx_index_set_contains} can be used to test if
@c a given integer @code{n} belongs to the index set.
@c @findex mtx_index_set_contains
@c @example
@c @code{bool mtx_index_set_contains(
@c     const struct mtx_index_set * index_set, int n);}
@c @end example


@c @node Creating distributed matrices and vectors
@c @section Creating distributed matrices and vectors
@c A number of functions are provided to more conveniently construct
@c distributed matrices and vectors. These are described in the following
@c subsections.


@c @node mtxdist_free
@c @subsection mtxdist_free

@c @findex mtxdist_free
@c Since a distributed matrix or vector represented by a @code{struct
@c mtxdist} allocates some storage for its data, the user is required to
@c free the allocated storage by calling @code{mtxdist_free} when they
@c are finished with the matrix or vector:
@c @example
@c @code{void mtxdist_free(
@c     struct mtxdist * mtxdist);}
@c @end example


@c @node Creating distributed vectors
@c @subsection Creating distributed vectors


@c @node Creating distributed matrices
@c @subsection Creating distributed matrices


@c @node Reading and writing distributed Matrix Market files
@c @section Reading and writing distributed Matrix Market files


@c @node Communicating matrices and vectors
@c @section Communicating matrices and vectors

@c The file @file{libmtx/mtx/mpi.h} defines functions that can be
@c used to communicate Matrix Market objects represented by the
@c @code{mtx} struct between MPI processes.


@c @node MPI errors
@c @subsection MPI errors

@c @cindex MPI errors
@c @findex mtxdiststrerror
@c In the event of an MPI-related error, then the above functions return
@c @code{MTX_ERR_MPI} and the argument @code{mpierrcode} is set to a
@c specific MPI error code. @code{mpierrcode} can then be used with the
@c function @code{mtxdiststrerror}, as described in @ref{Error handling}.


@c @node send receive broadcast
@c @subsection Send, receive and broadcast

@c The basic functions for communicating @code{struct mtx} objects are:
@c @example
@c @code{int mtx_send(
@c     const struct mtx * mtx,
@c     int dest,
@c     int tag,
@c     MPI_Comm comm,
@c     int * mpierrcode);

@c int mtx_recv(
@c     struct mtx * mtx,
@c     int source,
@c     int tag,
@c     MPI_Comm comm,
@c     int * mpierrcode);

@c int mtx_bcast(
@c     struct mtx * mtx,
@c     int root,
@c     MPI_Comm comm,
@c     int * mpierrcode);}
@c @end example
@c These functions are analogous to @code{MPI_Send}, @code{MPI_Recv} and
@c @code{MPI_Bcast}.
